# -*- coding: utf-8 -*-
"""Lesson 7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Yriqy7SwsTrjqEHe5MzOvfOm2M15eyv8

Pytorch Workflow
"""

import torch
from torch import nn # nn contains all of Pytorch's building block for neural network
import matplotlib.pyplot as plt

torch.__version__

"""Data preparing and loading


---

Machine learning is game of two parts:
1. Get data into a numerical representation
2. Build a model to learn patterns in that numerical representation

For this , we create known data using linear regression formula.

Using linear regression formula, y=mx+c we make straight line with known parameters.


---

Creating a dataset with linear regression
"""

#creating known parameters
weight =0.7
bias = 0.3

#creating
start = 0
end = 1

step =0.02
X= torch.arange(start,end,step).unsqueeze(dim=1)
Y= weight * X +bias
X[:10],Y[:10]

len(X),len(Y)

"""Splitting data into training and test set

(One of the most importatnt concepts of machine learning in general)
"""

#Create a train/test split

train_split = int(0.8 *len(X))
X_train,Y_train = X[:train_split] ,Y[:train_split]
X_test,Y_test = X[train_split:],Y[train_split:]

len(X_train),len(Y_train),len(X_test),len(Y_test)

X_train,Y_train

"""Visualizing data better"""

def plot_predictions(train_data= X_train,
                     train_label=Y_train,
                     test_data= X_test,
                     test_labels=Y_test,
                     predictions=None):

  #Plots training data,test data and compare predictions.

  plt.figure(figsize=(10,7))

  #Plot training data in blue
  plt.scatter(train_data,train_label,c="b",s=4,label="Training data")

  #Plot test data in green
  plt.scatter(test_data,test_labels,c="g",s=4,label="Testing data")

  if predictions is not None:
    plt.scatter(test_data,predictions ,c="r",s=4 ,label ="Predictions")

  plt.legend(prop={"size":14})

plot_predictions()

"""Building our first Pytorch Model"""

#Create linear regression model class

#What our model does?
'''#Start with random values(weight & bias)
#Look at training data and adjust the random values to better represent(or get closer to )
the ideal values(the weight and bias values we used to create the data)
'''

#How does it do so? There are two main algorithms:
#Gradient descent
#Backpropogation


class LinearRegressionModel(nn.Module):#almost everything in Pytorch inherits from nn.Module (neural network modules)
     def __init__(self):
        super().__init__()
        self.weights = nn.Parameter(torch.randn(1,
                                                requires_grad=True,
                                                dtype=torch.float))
        self.bias = nn.Parameter(torch.randn(1,
                                             requires_grad=True,
                                             dtype=torch.float))

     def forward(self,x:torch.Tensor)-> torch.Tensor:
         return self.weights * x + self.bias

